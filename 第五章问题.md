## 第五章 决策树

概念解释：

- P74：熵，条件熵，信息增益，信息增益比，互信息的概念
- P74：互信息和信息增益的区别
- P76：ID3、C4.5、CART（P81包括回归和分类）分别使用什么作为特征选择的标准
- 为什么ID3、C4.5只能处理分类问题，而不能处理回归问题
- P79：如何理解决策树的损失函数
- P79：ID3和C4.5剪枝算法
- P81：CART生成回归树算法
- P87：CART剪枝算法（结束条件是什么，根节点和两个叶节点构成的树？）

问题：

- 决策树为什么是概率模型（solved：特征空间上与类空间的条件概率分布）
- P70：为什么说决策树学习的损失函数是正则化的极大似然函数
- P72：如何从公式上证明"熵越大，随机变量的不确定性就越大"
- P76：为什么需要信息增益比？信息增益有什么缺点？信息增益比为什么可以优化？
- P76：为什么说ID3相当于用极大似然法进行概率模型的选择
- P84：比较CART和ID3的生成方法区别
  - CART每次不仅仅要找最优特征，还要找最优切分点，但是ID3每次只需要找到最优特征，下面的n个子树代表当前特征下n个不同的取值
  - CART所得结点都是叶子结点
- P86：为什么要在T0中减去g(t)**最小**的Tt（g(t)代表损失函数减少的程度）
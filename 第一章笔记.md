**简要介绍：决策树，朴素贝叶斯，隐马尔可夫，条件随机场，混合高斯** **P11**

决策树：从树根到树叶的每一条路径，都是一个条件概率。$P(Y|X_1,X_2,X_3,...)$

朴素贝叶斯：条件独立性假设

隐马尔可夫：标注问题。可观测变量由不可观测的隐状态H以一定概率产生；隐状态H服从马尔科夫性

（线性链）条件随机场：标注问题。X是输入，Y是输出的标注。输出序列Y中$Y_i$在输入序列X给定的条件下，仅与前后$Y_{i-1},Y_{i+1}$有关$P(Y_i|X,Y_1,...Y_{i-1},Y_{i+1},...Y_n)=P(Y_i|X,Y_{i-1},Y_{i+1})$

混合高斯：聚类。假设数据是由若干个高斯分布生成，学习这几个高斯分布的参数μ和σ，带入高斯分布X根据某判别属于哪一类

Adaboost：提升方法。先找到弱分类器（线性分类器），然后反复学习，得到一系列弱分类器，组合他们，构成一个强分类器。

|                | 决策树 | 朴素贝叶斯 | 隐马尔可夫 | 条件随机场 | 混合高斯 | 逻辑回归 | 感知机 | SVM      | k近邻 | AdaBoost | k均值 | 神经网络 |
| -------------- | ------ | ---------- | ---------- | ---------- | -------- | -------- | ------ | -------- | ----- | -------- | ----- | -------- |
| is概率模型？   | √      | √          | √          | √          | √        |          |        |          |       |          |       |          |
| is线性模型？   |        |            |            |            |          |          | √      | 线性SVM√ | √     |          | √     |          |
| is参数化模型？ |        | √          |            |            | √        | √        | √      |          |       |          | √     |          |

   \



**请解释图1.6** **P14**

极大似然
$$
\hat\theta=\mathop {argmax}_{\theta}P(D|\theta)
$$
贝叶斯估计
$$
\hat{P}(\theta|D)=\frac {P(\theta)P(D|\theta)}{P(D)}
$$
答：

最大似然和贝叶斯估计的异同：

都是**参数化**模型，对假设θ就是参数

不同：

1、最大似然只取最大可能的假设，θ是一个固定形式的未知变量

2、贝叶斯估计承认所有假设存在的合理性，并分配权重；θ是一个有某种先验分布的随机变量

如果是均匀分布，再让后验概率最大，那就是最大似然。

来自 <https://zhuanlan.zhihu.com/p/43873322>   

\



**请解释核函数的作用?** **P15**

答：

核函数
$$
K(x_1,x_2)=\langle\phi(x_1),\phi(x_2)\rangle
$$
直接计算内积

隐式地将原始特征映射到高维空间  

 \



**经验风险最小化与结构风险最小化有何异同？** **P18**

答：

 **① 频率学派**

他们认为世界是确定的。他们直接为事件本身建模，也就是说事件在多次重复实验中趋于一个稳定的值p，那么这个值就是该事件的概率。

他们认为模型参数是个定值，希望通过类似解方程组的方式从数据中求得该未知数。这就是频率学派使用的参数估计方法-**极大似然估计（MLE）**，这种方法往往在大数据量的情况下可以很好的还原模型的真实情况。

**② 贝叶斯派**

他们认为世界是不确定的，因获取的信息不同而异。假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。 他们不试图对事件本身进行建模，而是从旁观者的角度来说。因此对于同一个事件，不同的人掌握的先验不同的话，那么他们所认为的事件状态也会不同。

他们认为模型参数源自某种潜在分布，希望从数据中推知该分布。对于数据的观测方式不同或者假设不同，那么推知的该参数也会因此而存在差异。这就是贝叶斯派视角下用来估计参数的常用方法-**最大后验概率估计（MAP）**，这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了。

https://zhuanlan.zhihu.com/p/40024110

  \



**泛化误差上界与哪些因素有关？** **P26**

答：

样本量N

假设空间大小d

训练误差R^(f)

   \



**什么是生成模型？什么是判别模型？** **P28**

答：

生成模型还原了联合概率分布P(X,Y)，当有因变量时，就能用生成模型了

判别模型只根据条件概率P(Y|X)，准确率更高  

  \



**为什么F1=精确率和召回率的调和均值，而不是算数均值？** **P29**

**存疑，不会推导**  

  \



**机器翻译是不是标注问题？** **P31**

答：

不是，in和out长度不一致



 